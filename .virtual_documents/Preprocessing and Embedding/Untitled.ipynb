import pandas as pd


df = pd.read_csv("IMDB Dataset.csv")


df.head()


df.shape


df = df.head(100)


df.shape


## First lets turn all the text to small. To do that we can use python simple string function


type(df['review'][3])


df['review'] = df['review'].str.lower()


df['review']


df['review'][1]


## Here we can see multiple html tags. we need to remove those tags. Here we can use butisoup. This python library helps us to extrat data from HTML and XML


from bs4 import BeautifulSoup


BeautifulSoup(df['review'][1], "html.parser").get_text()


##lets applly it to whole column


df['review'] = df['review'].apply(lambda x: BeautifulSoup(x, 'html.parser').get_text())


df['review']


## Now lets handle the puntuation 


import string 


exclude = string.punctuation


print(exclude)


type(exclude)


test_string = df['review'][1]


def remove_punctuation(text):
    for ch in exclude:
        text = text.replace(ch, '')

    return text


test_string = remove_punctuation(test_string)


print(test_string)


## We we can translate method of sting


def remove_punc(text):
    text = text.translate(str.maketrans('','', exclude))
    return text


test_string = remove_punc(test_string)


print(test_string)


df['review'] = df['review'].apply(remove_punc)


df['review']


## Now lets remove the stopwords


from nltk.corpus import stopwords


stopwords.words('english')


def remove_stopwords(text):
    new_text = []
    for word in text.split():
        if word in stopwords.words('english'):
            new_text.append('')
        else:
            new_text.append(word)
    return ' '.join(new_text)


test_string


test_string = remove_stopwords(test_string)


print(test_string)


df['review'] = df['review'].apply(remove_stopwords)


df['review']


## now lets tokenize and stemp it
import nltk
from nltk.stem import PorterStemmer
nltk.download('punkt')
from nltk.tokenize import word_tokenize


def tokens(text):
    words = word_tokenize(text)
    return words


tokens("I am shih")



